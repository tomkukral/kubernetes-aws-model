parameters:
  _param:
    salt_minion_ca_host: ${_param:infra_config_hostname}.${_param:cluster_domain}
    salt_minion_ca_authority: salt_master_ca

    # kubernetes settings
    kubernetes_admin_user: admin
    kubernetes_admin_password: sbPfel23ZigJF3Bm
    kubernetes_admin_token: PpP6Mm3pAoPVqcKOKUu0x1dh7b1959Fi
    kubernetes_kubelet_token: JJ2PKHxjiU6EYvIt18BqwdSK1HvWh8pt
    kubernetes_kube-proxy_token: jT0hJk9L6cIw5UpYDNhsRwcj3Z2n62B6
    kubernetes_scheduler_token: VgkUHfrW07zNxrb0ucFyX7NBnSJN9Xp6
    kubernetes_controller-manager_token: uXrdZ1YKF6qlYm3sHje2iEXMGAGDWOIU
    kubernetes_dns_token: 0S1I4iJeFjq5fopPwwCwTp3xFpEZfeUl
    etcd_initial_token: IN7KaRMSo3xkGxkjAAPtkRkAgqN4ZNRq

    # images
    kubernetes_calicoctl_image: calico/ctl:v3.1.0
    kubernetes_calico_image: calico/node:v3.1.0
    kubernetes_calico_cni_image: calico/cni:v3.1.0
    kubernetes_hyperkube_image: gcr.io/google_containers/hyperkube-amd64:v1.10.2

    # addresses and hostnames
    kubernetes_internal_api_address: 10.254.0.1
    kubernetes_control_hostname: ctl
    kubernetes_control_address: 10.0.10.10
    kubernetes_control_node01_hostname: ctl01
    kubernetes_control_node02_hostname: ctl02
    kubernetes_control_node03_hostname: ctl03
    kubernetes_control_node01_address: 10.0.10.10
    kubernetes_control_node02_address: 10.0.10.12
    kubernetes_control_node03_address: 10.0.10.13

    cluster_vip_address: ${_param:kubernetes_control_address}
    cluster_local_address: ${_param:single_address}

    # etcd stuff
    cluster_node01_hostname: ${_param:kubernetes_control_node01_hostname}
    cluster_node01_address: ${_param:kubernetes_control_node01_address}
    cluster_node01_port: 4001
    cluster_node02_hostname: ${_param:kubernetes_control_node02_hostname}
    cluster_node02_address: ${_param:kubernetes_control_node02_address}
    cluster_node02_port: 4001
    cluster_node03_hostname: ${_param:kubernetes_control_node03_hostname}
    cluster_node03_address: ${_param:kubernetes_control_node03_address}
    cluster_node03_port: 4001

    # calico
    calico_private_network: 10.0.128.0
    calico_private_netmask: 17

  kubernetes:
    common:
      cloudprovider:
        enabled: True
        provider: aws
  linux:
    network:
      resolv:
        domain: ${_param:cluster_domain}
        options:
          - ndots:5
          - timeout:2
          - attempts:2
      host:
        #ctl:
        #  address: ${_param:kubernetes_control_address}
        #  names:
        #  - ${_param:kubernetes_control_hostname}
        #  - ${_param:kubernetes_control_hostname}.${_param:cluster_domain}
        ctl01:
          address: ${_param:kubernetes_control_node01_address}
          names:
          - ${_param:kubernetes_control_node01_hostname}
          - ${_param:kubernetes_control_node01_hostname}.${_param:cluster_domain}
        ctl02:
          address: ${_param:kubernetes_control_node02_address}
          names:
          - ${_param:kubernetes_control_node02_hostname}
          - ${_param:kubernetes_control_node02_hostname}.${_param:cluster_domain}
        ctl03:
          address: ${_param:kubernetes_control_node03_address}
          names:
          - ${_param:kubernetes_control_node03_hostname}
          - ${_param:kubernetes_control_node03_hostname}.${_param:cluster_domain}
    system:
      rc:
        local: |
          #!/bin/bash
          #
          # rc.local
          #
          ######### This file is managed by Salt! ##########
          # This script is executed at the end of each multiuser runlevel.
          # Make sure that the script will "exit 0" on success or any other
          # value on error.
          #
          ip r | grep "10.254.0.0" > /dev/null || ip r a 10.254.0.0/16 dev eth0
          exit 0
